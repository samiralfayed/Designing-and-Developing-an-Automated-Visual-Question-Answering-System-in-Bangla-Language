{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyB0yymfReaT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.layers import GlobalAveragePooling2D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqFwBr-qTWbo",
        "outputId": "cc7554dd-9cf5-49c6-d844-75af6b95bd4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G10RaRSsRrY1"
      },
      "outputs": [],
      "source": [
        "# Load the JSON files\n",
        "with open('/content/drive/MyDrive/cap/bangla dataset/train_questions_save (1).json', 'r') as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/cap/bangla dataset/train_questions_save (1).json', 'r') as f:\n",
        "    test_data = json.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxF7H25QRsXg"
      },
      "outputs": [],
      "source": [
        "# Define image and question data\n",
        "train_image_ids = []\n",
        "train_questions = []\n",
        "train_answers = []\n",
        "test_image_ids = []\n",
        "test_questions = []\n",
        "test_answers = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-mHFaj9RuZK"
      },
      "outputs": [],
      "source": [
        "for key in train_data:\n",
        "    train_image_ids.append(train_data[key]['image_id'])\n",
        "    train_questions.append(train_data[key]['question'])\n",
        "    train_answers.append(train_data[key]['answer'])\n",
        "\n",
        "for key in test_data:\n",
        "    test_image_ids.append(test_data[key]['image_id'])\n",
        "    test_questions.append(test_data[key]['question'])\n",
        "    test_answers.append(test_data[key]['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAjW-SvYRwQL"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess images\n",
        "image_dir = '/content/drive/MyDrive/cap/bangla dataset/Images/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCkfG399RyIq"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img = img.convert('RGB')\n",
        "    img = img.resize((224, 224))\n",
        "    img = img_to_array(img)\n",
        "    img = img / 255.0\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEjVIziQR0Ls"
      },
      "outputs": [],
      "source": [
        "train_images = [preprocess_image(image_dir + image_id + '.png') for image_id in train_image_ids]\n",
        "train_images = np.array(train_images)\n",
        "\n",
        "test_images = [preprocess_image(image_dir + image_id + '.png') for image_id in test_image_ids]\n",
        "test_images = np.array(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLY4PMFDR2YD"
      },
      "outputs": [],
      "source": [
        "# Process questions\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_questions)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqyF9NhbR2Yo"
      },
      "outputs": [],
      "source": [
        "train_question_sequences = tokenizer.texts_to_sequences(train_questions)\n",
        "train_question_sequences = pad_sequences(train_question_sequences, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXn_SyNmR7_U"
      },
      "outputs": [],
      "source": [
        "test_question_sequences = tokenizer.texts_to_sequences(test_questions)\n",
        "test_question_sequences = pad_sequences(test_question_sequences, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AFBIf0OR-lU",
        "outputId": "ed75d846-a510-4924-e347-f96a9967f976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "# Define the VGG16 model\n",
        "image_input = Input(shape=(224, 224, 3))\n",
        "cnn_model = VGG16(weights='imagenet', include_top=False, input_tensor=image_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cC3jwwTSl_O"
      },
      "outputs": [],
      "source": [
        "# Add a Global Average Pooling layer after the VGG16 model\n",
        "image_features = cnn_model.output\n",
        "image_features = GlobalAveragePooling2D()(image_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm6jyLEnSo1I"
      },
      "outputs": [],
      "source": [
        "# Freeze the layers of the CNN model\n",
        "for layer in cnn_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB0epOSHSsx-",
        "outputId": "65137ece-c660-41b2-a858-f081c1b2a969"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 597s 19s/step\n",
            "31/31 [==============================] - 582s 19s/step\n"
          ]
        }
      ],
      "source": [
        "# Extract image features\n",
        "train_image_features = cnn_model.predict(train_images)\n",
        "test_image_features = cnn_model.predict(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UK8BmS9TStmc"
      },
      "outputs": [],
      "source": [
        "# Define the LSTM model for processing questions\n",
        "question_input = Input(shape=(None,))\n",
        "embedding_layer = Embedding(vocab_size, 300, mask_zero=True)(question_input)\n",
        "lstm_layer = LSTM(256)(embedding_layer)\n",
        "\n",
        "# Combine image and question features\n",
        "combined_features = Concatenate()([image_features, lstm_layer])\n",
        "output = Dense(512, activation='relu')(combined_features)\n",
        "output = Dense(vocab_size, activation='softmax')(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1JDkAEbLSv5N"
      },
      "outputs": [],
      "source": [
        "# Create the final model\n",
        "model = Model(inputs=[cnn_model.input, question_input], outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r0WI7NC7S0OA"
      },
      "outputs": [],
      "source": [
        "label_mapping = {'বানর বার': 0, 'বসা': 1, 'না': 2, 'মল': 3, 'ঠিক': 4, 'সাদা': 4, 'হ্যাঁ': 6, 'কুকুর': 7, 'বাদামী': 8, 'দুই': 9, 'চার': 10, 'পাঁচ': 11, 'সবুজ': 12, 'বাজানো': 13, 'বিড়াল': 14, 'নীল': 15, 'টেবিল': 16, 'ছেলে': 17, 'রৌদ্রোজ্জ্বল': 18, 'তিন': 19, 'কালো': 20, 'গাছ': 21, 'এক': 22, 'বেঞ্চ': 23, 'ধূসর': 24, 'হলুদ': 25, 'পাখি': 26, 'মেয়ে': 27, 'মদ': 28, 'মানুষ': 29, 'লাল': 30, 'বই': 31, 'হাড়': 32, 'সকার': 33, 'পাই': 34, 'লগ': 35, 'বেসবল': 36, 'ফুটবল': 37, 'কমলা': 38, 'পালঙ্ক': 39, 'দাঁড়িয়ে': 40, '0': 41, 'মহিলা': 42, 'খাবার': 43, 'মেঝে': 44, 'কাঠবিড়াল': 45, 'পাটি': 46, 'ঘুমাচ্ছেন': 47, 'আপেল': 48, 'বাইক': 49, 'উদ্ভিদ': 50, 'কম্বল': 51, 'ঘাস': 52, 'চেয়ার': 53, 'বাম': 54, 'কিছুই না': 55}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vXRU0aGZS20O"
      },
      "outputs": [],
      "source": [
        "train_label_encoded = [label_mapping[label] for label in train_answers]\n",
        "train_label_encoded = np.array(train_label_encoded, dtype=np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cF_Afn5hS5Lk"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "goBeDNEzmF5N",
        "outputId": "32cd0da7-b587-4bb5-bd6c-583f78150a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "61/61 [==============================] - 593s 10s/step - loss: 3.1902 - accuracy: 0.3525\n",
            "Epoch 2/15\n",
            "61/61 [==============================] - 590s 10s/step - loss: 2.0924 - accuracy: 0.3699\n",
            "Epoch 3/15\n",
            "61/61 [==============================] - 589s 10s/step - loss: 1.7851 - accuracy: 0.4170\n",
            "Epoch 4/15\n",
            "61/61 [==============================] - 589s 10s/step - loss: 1.5232 - accuracy: 0.4836\n",
            "Epoch 5/15\n",
            "61/61 [==============================] - 586s 10s/step - loss: 1.3054 - accuracy: 0.5922\n",
            "Epoch 6/15\n",
            "61/61 [==============================] - 586s 10s/step - loss: 1.0991 - accuracy: 0.6650\n",
            "Epoch 7/15\n",
            "61/61 [==============================] - 585s 10s/step - loss: 0.9422 - accuracy: 0.7152\n",
            "Epoch 8/15\n",
            "61/61 [==============================] - 583s 10s/step - loss: 0.8169 - accuracy: 0.7357\n",
            "Epoch 9/15\n",
            "61/61 [==============================] - 584s 10s/step - loss: 0.7481 - accuracy: 0.7572\n",
            "Epoch 10/15\n",
            "12/61 [====>.........................] - ETA: 7:44 - loss: 0.6137 - accuracy: 0.8125"
          ]
        }
      ],
      "source": [
        "history = model.fit([train_images, train_question_sequences], np.array(train_label_encoded), epochs=15, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DE_c50aKmJLJ"
      },
      "outputs": [],
      "source": [
        "# Plotting the loss and accuracy on the same graph\n",
        "epochs = range(1, len(history.history['loss']) + 1)\n",
        "\n",
        "plt.plot(epochs, history.history['loss'], label='Training Loss')\n",
        "plt.plot(epochs, history.history['accuracy'], label='Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Training Loss and Accuracy over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O14SMk8zS8VE"
      },
      "outputs": [],
      "source": [
        "test_answers = [item['answer'] for _, item in test_data.items()]\n",
        "\n",
        "test_label_encoded = [label_mapping[label] for label in test_answers]\n",
        "test_label_encoded = np.array(test_label_encoded, dtype=np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ww8Z9C2S8Vq"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model.evaluate([test_images, test_question_sequences], test_label_encoded)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k08vf9ZZS0EI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hes_ciT6TBKA"
      },
      "outputs": [],
      "source": [
        "# Provide an image and question\n",
        "input_image_path = '/content/drive/MyDrive/bangla dataset/Images/2.png'\n",
        "input_question = 'কেউ কি সোফায় বসে আছে?'\n",
        "\n",
        "# Set the maximum sequence length\n",
        "max_question_length = 100\n",
        "\n",
        "# Preprocess the input image\n",
        "input_image = preprocess_image(input_image_path)\n",
        "input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Tokenize and preprocess the input question\n",
        "input_question_sequence = tokenizer.texts_to_sequences([input_question])\n",
        "input_question_sequence = pad_sequences(input_question_sequence, maxlen=max_question_length)\n",
        "\n",
        "# Make prediction on the input\n",
        "prediction = model.predict([input_image, input_question_sequence])\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "# Decode the predicted label\n",
        "label_mapping_reverse = {v: k for k, v in label_mapping.items()}\n",
        "predicted_answer = label_mapping_reverse[predicted_label]\n",
        "\n",
        "# Print the predicted answer\n",
        "print(\"Predicted Answer:\", predicted_answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXWOxLEBmNO6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Assuming you have a function preprocess_image() and a tokenizer\n",
        "# Also, you need to define the label_mapping dictionary and the model\n",
        "\n",
        "# Function to check if a string is empty or consists of only spaces\n",
        "def is_empty_or_spaces(s):\n",
        "    return s.strip() == \"\"\n",
        "\n",
        "input_image_path = input(\"Enter image path: \").strip()\n",
        "input_question = input(\"Enter question: \").strip()\n",
        "\n",
        "# Check if either image path or question is empty\n",
        "if is_empty_or_spaces(input_image_path) and is_empty_or_spaces(input_question):\n",
        "    print(\"Please enter an image path or a question.\")\n",
        "else:\n",
        "    # Set the maximum sequence length\n",
        "    max_question_length = 100\n",
        "\n",
        "    # Preprocess the input image if not empty\n",
        "    input_image = None\n",
        "    if not is_empty_or_spaces(input_image_path):\n",
        "        input_image = preprocess_image(input_image_path)\n",
        "        input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Tokenize and preprocess the input question if not empty\n",
        "    input_question_sequence = None\n",
        "    if not is_empty_or_spaces(input_question):\n",
        "        input_question_sequence = tokenizer.texts_to_sequences([input_question])\n",
        "        input_question_sequence = pad_sequences(input_question_sequence, maxlen=max_question_length)\n",
        "\n",
        "    if input_image is not None and input_question_sequence is not None:\n",
        "        # Make prediction on the input\n",
        "        prediction = model.predict([input_image, input_question_sequence])\n",
        "        predicted_label = np.argmax(prediction)\n",
        "\n",
        "        # Decode the predicted label\n",
        "        label_mapping_reverse = {v: k for k, v in label_mapping.items()}\n",
        "        predicted_answer = label_mapping_reverse[predicted_label]\n",
        "\n",
        "        # Print the predicted answer\n",
        "        print(\"Predicted Answer:\", predicted_answer)\n",
        "    else:\n",
        "        print(\"Please provide either an image or a question.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}